{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPModel, CLIPTokenizer\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'somef' from '/home/jenifer/.local/lib/python3.10/site-packages/somef/__init__.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(text_list):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=3000, sublinear_tf=True)\n",
    "    vectors = vectorizer.fit_transform(text_list)\n",
    "    return vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentence_embeddings(text_list, batch_size=256):\n",
    "    embeddings = []\n",
    "    text_list = [text.strip() for text in text_list]\n",
    "\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        batch_embeddings = model_bert.encode(batch)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    # Concatenate all batch embeddings\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clip_embeddings(text_list, batch_size=256):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model_clip.get_text_features(**inputs).cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_with_undersampling(X, y, embedding_name, source_text):\n",
    "    # Stratified K-Fold for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Random undersampling for balancing classes\n",
    "    #rus = RandomUnderSampler(sampling_strategy='not minority', random_state=42)\n",
    "\n",
    "    # Create the RandomForest model\n",
    "    base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # One-vs-Rest Classifier with custom pipeline that applies undersampling\n",
    "    clf = OneVsRestClassifier(\n",
    "        make_pipeline(RandomUnderSampler(sampling_strategy='not minority', random_state=42), base_rf),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f'Fold Results for {embedding_name} (OvR Random Forest) - {source_text}:')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n",
    "        print('-----------------------------------')\n",
    "\n",
    "    # Average metrics over all folds\n",
    "    print(f'Final Cross-Validated Results for {embedding_name} (OvR Random Forest) - {source_text}:')\n",
    "    print(f'Average Accuracy: {sum(accuracy_scores)/len(accuracy_scores):.4f}')\n",
    "    print(f'Average Precision: {sum(precision_scores)/len(precision_scores):.4f}')\n",
    "    print(f'Average Recall: {sum(recall_scores)/len(recall_scores):.4f}')\n",
    "    print(f'Average F1-Score: {sum(f1_scores)/len(f1_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering_metrics(X, y, embedding_name, source_text):\n",
    "    print(f'Clustering metrics for {embedding_name} - {source_text}:')\n",
    "    # Calculate metrics\n",
    "    silhouette_avg = silhouette_score(X, y)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, y)\n",
    "    davies_bouldin = davies_bouldin_score(X, y)\n",
    "    \n",
    "    # Return results in a dictionary\n",
    "    metrics = {\n",
    "        'Silhouette Score': silhouette_avg,\n",
    "        'Calinski-Harabasz Index': calinski_harabasz,\n",
    "        'Davies-Bouldin Index': davies_bouldin\n",
    "    }\n",
    "    \n",
    "    table = [[\"Metric\", \"Score\"]]\n",
    "    for metric, score in metrics.items():\n",
    "        table.append([metric, f\"{score:.4f}\"])\n",
    "    \n",
    "    print(f'Clustering metrics for {embedding_name} (OvR Random Forest) - {source_text}:')\n",
    "    print(f'Silhouette Score: {silhouette_avg:.4f}')\n",
    "    print(f'Calinski-Harabasz Index: {calinski_harabasz:.4f}')\n",
    "    print(f'Davies-Bouldin Index: {davies_bouldin:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load data')\n",
    "with open('../data/final_dataset.json', 'r') as f:\n",
    "    papers_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(papers_data)\n",
    "print(f'Number of samples: {df.shape[0]}')\n",
    "\n",
    "titles = df['paper_title'].tolist()\n",
    "abstracts = df['abstract'].tolist()\n",
    "readmes = df['github_readme_content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load data for somef decriptions')\n",
    "with open('../data/filtered_data.json', 'r') as f:\n",
    "    papers_data_somef = json.load(f)\n",
    "\n",
    "df_somef = pd.DataFrame(papers_data_somef)\n",
    "print(f'Number of samples: {df_somef.shape[0]}')\n",
    "\n",
    "somef = df_somef['somef_descriptions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load data for github titles and keywords')\n",
    "with open('../data/filtered_data_complete.json', 'r') as f:\n",
    "    papers_data_complete = json.load(f)\n",
    "\n",
    "df_complete = pd.DataFrame(papers_data_complete)\n",
    "print(f'Number of samples: {df_complete.shape[0]}')\n",
    "github_title = df_complete['github_repo_title'].tolist()\n",
    "github_keywords = df_complete['github_keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['main_collection_area']\n",
    "y_somef = df_somef['main_collection_area']\n",
    "y_complete = df_complete['main_collection_area']\n",
    "num_clusters = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_embeddings = compute_tfidf(titles)\n",
    "train_random_forest_with_undersampling(tfidf_embeddings, y, 'TF-IDF', 'Title')\n",
    "evaluate_clustering_metrics(tfidf_embeddings, y, 'TF-IDF', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(titles)\n",
    "train_random_forest_with_undersampling(sentence_embeddings, y, 'Sentence Transformer', 'Title')\n",
    "evaluate_clustering_metrics(sentence_embeddings, y, 'Sentence Transformer', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = compute_clip_embeddings(titles)\n",
    "train_random_forest_with_undersampling(clip_embeddings, y, 'CLIP', 'Title')\n",
    "evaluate_clustering_metrics(clip_embeddings, y, 'CLIP', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_embeddings = compute_tfidf(abstracts)\n",
    "train_random_forest_with_undersampling(tfidf_embeddings, y, 'TF-IDF', 'Abstract')\n",
    "evaluate_clustering_metrics(tfidf_embeddings, y, 'TF-IDF', 'Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(abstracts)\n",
    "train_random_forest_with_undersampling(sentence_embeddings, y, 'Sentence Transformer', 'Abstract')\n",
    "evaluate_clustering_metrics(sentence_embeddings, y, 'Sentence Transformer', 'Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = compute_clip_embeddings(abstracts)\n",
    "train_random_forest_with_undersampling(clip_embeddings, y, 'CLIP', 'Abstract')\n",
    "evaluate_clustering_metrics(clip_embeddings, y, 'CLIP', 'Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_embeddings = compute_tfidf(readmes)\n",
    "train_random_forest_with_undersampling(tfidf_embeddings, y, 'TF-IDF', 'GitHub README Content')\n",
    "evaluate_clustering_metrics(tfidf_embeddings, y, 'TF-IDF', 'GitHub README Content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(readmes)\n",
    "train_random_forest_with_undersampling(sentence_embeddings, y, 'Sentence Transformer', 'GitHub README Content')\n",
    "evaluate_clustering_metrics(sentence_embeddings, y, 'Sentence Transformer', 'GitHub README Content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = compute_clip_embeddings(readmes)\n",
    "train_random_forest_with_undersampling(clip_embeddings, y, 'CLIP', 'GitHub README Content')\n",
    "evaluate_clustering_metrics(clip_embeddings, y, 'CLIP', 'GitHub README Content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_embeddings = compute_tfidf(somef)\n",
    "train_random_forest_with_undersampling(tfidf_embeddings, y_somef, 'TF-IDF', 'SOMEF descriptions')\n",
    "evaluate_clustering_metrics(tfidf_embeddings, y_somef, 'TF-IDF', 'SOMEF descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(somef)\n",
    "train_random_forest_with_undersampling(sentence_embeddings, y_somef, 'Sentence Transformer', 'SOMEF descriptions')\n",
    "evaluate_clustering_metrics(sentence_embeddings, y_somef, 'Sentence Transformer', 'SOMEF descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = compute_clip_embeddings(somef)\n",
    "train_random_forest_with_undersampling(clip_embeddings, y_somef, 'CLIP', 'SOMEF descriptions')\n",
    "evaluate_clustering_metrics(clip_embeddings, y_somef, 'CLIP', 'SOMEF descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_embeddings = compute_tfidf(github_title)\n",
    "train_random_forest_with_undersampling(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Title')\n",
    "evaluate_clustering_metrics(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(github_title)\n",
    "train_random_forest_with_undersampling(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Title')\n",
    "evaluate_clustering_metrics(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = compute_clip_embeddings(github_title)\n",
    "train_random_forest_with_undersampling(clip_embeddings, y_complete, 'CLIP', 'GitHub Title')\n",
    "evaluate_clustering_metrics(clip_embeddings, y_complete, 'CLIP', 'GitHub Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_embeddings = compute_tfidf(github_keywords)\n",
    "train_random_forest_with_undersampling(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Keywords')\n",
    "evaluate_clustering_metrics(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(github_keywords)\n",
    "train_random_forest_with_undersampling(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Keywords')\n",
    "evaluate_clustering_metrics(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = compute_clip_embeddings(github_keywords)\n",
    "train_random_forest_with_undersampling(clip_embeddings, y_complete, 'CLIP', 'GitHub Keywords')\n",
    "evaluate_clustering_metrics(clip_embeddings, y_complete, 'CLIP', 'GitHub Keywords')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
